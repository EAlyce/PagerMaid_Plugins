import os
import shutil
import tarfile
import json
import asyncio
import datetime
import re
import tempfile
import secrets

from pagermaid.hook import Hook
from pagermaid.listener import listener
from pagermaid.enums import Message
from pagermaid.services import bot, scheduler

# ç»Ÿä¸€æ—¶åŒºï¼šåŒ—äº¬ï¼ˆUTC+8ï¼‰
BJ_TZ = datetime.timezone(datetime.timedelta(hours=8), name="UTC+8")


def now_bj():
    return datetime.datetime.now(BJ_TZ)


# æŒä¹…åŒ–ç¡®è®¤æœºåˆ¶
def get_hf_confirm_file():
    """è·å–hfç¡®è®¤æ–‡ä»¶è·¯å¾„"""
    return os.path.join(get_program_dir(), "data", "hf_confirm.json")


def save_hf_confirm_request(backup_info):
    """ä¿å­˜hfç¡®è®¤è¯·æ±‚ä¿¡æ¯"""
    confirm_file = get_hf_confirm_file()
    os.makedirs(os.path.dirname(confirm_file), exist_ok=True)

    confirm_data = {
        "timestamp": now_bj().isoformat(),
        "backup_info": backup_info,
        "expires_at": (now_bj() + datetime.timedelta(minutes=5)).isoformat(),
    }

    with open(confirm_file, "w", encoding="utf-8") as f:
        json.dump(confirm_data, f, ensure_ascii=False, indent=2)


def load_hf_confirm_request():
    """åŠ è½½hfç¡®è®¤è¯·æ±‚ä¿¡æ¯"""
    confirm_file = get_hf_confirm_file()
    if not os.path.exists(confirm_file):
        return None

    try:
        with open(confirm_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        expires_at = datetime.datetime.fromisoformat(data["expires_at"])
        if now_bj() > expires_at:
            os.remove(confirm_file)
            return None

        return data
    except Exception:
        try:
            os.remove(confirm_file)
        except Exception:
            pass
        return None


def clear_hf_confirm_request():
    """æ¸…é™¤hfç¡®è®¤è¯·æ±‚"""
    confirm_file = get_hf_confirm_file()
    try:
        if os.path.exists(confirm_file):
            os.remove(confirm_file)
    except Exception:
        pass


def get_program_dir():
    return os.getcwd()


def get_config_file():
    """è·å–é…ç½®æ–‡ä»¶è·¯å¾„"""
    return os.path.join(get_program_dir(), "data", "bf_config.json")


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_file = get_config_file()
    if os.path.exists(config_file):
        try:
            with open(config_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            pass
    return {}


def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    config_file = get_config_file()
    os.makedirs(os.path.dirname(config_file), exist_ok=True)
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)


# å®šæ—¶ä»»åŠ¡é…ç½®å­˜å–
def get_cron_expr():
    cfg = load_config()
    expr = cfg.get("cron_expr")
    if isinstance(expr, str) and expr.strip():
        return expr.strip()
    return None


def set_cron_expr(expr: str | None):
    cfg = load_config()
    if expr and expr.strip():
        cfg["cron_expr"] = expr.strip()
    else:
        cfg.pop("cron_expr", None)
    save_config(cfg)


def get_cron_last_run():
    """è·å–æœ€è¿‘ä¸€æ¬¡å®šæ—¶è§¦å‘æ—¶é—´ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œæ— åˆ™è¿”å› None"""
    cfg = load_config()
    val = cfg.get("cron_last_run")
    if isinstance(val, str) and val.strip():
        return val.strip()
    return None


def set_cron_last_run(ts: str):
    """ä¿å­˜æœ€è¿‘ä¸€æ¬¡å®šæ—¶è§¦å‘æ—¶é—´ï¼ˆå­—ç¬¦ä¸²ï¼‰"""
    cfg = load_config()
    cfg["cron_last_run"] = ts
    save_config(cfg)


def _parse_cron_field(field: str, min_v: int, max_v: int):
    """è§£æå•ä¸ª cron å­—æ®µï¼Œè¿”å›å…è®¸çš„æ•´æ•°é›†åˆã€‚
    æ”¯æŒ: "*", "*/n", å…·ä½“æ•°å­—, é€—å·åˆ—è¡¨, åŒºé—´a-b, ä»¥åŠç»“åˆæ­¥è¿› a-b/nã€‚
    ç®€åŒ–å®ç°ï¼Œæ»¡è¶³å¸¸è§ä½¿ç”¨ã€‚
    """
    field = field.strip()
    values = set()

    def add_range(a, b, step=1):
        a = max(min_v, int(a))
        b = min(max_v, int(b))
        if step <= 0:
            step = 1
        for v in range(a, b + 1, step):
            values.add(v)

    if field == "*":
        return set(range(min_v, max_v + 1))

    # */n
    if field.startswith("*/"):
        step = int(field[2:])
        add_range(min_v, max_v, step)
        return values

    # é€—å·åˆ†éš”çš„å¤šé¡¹
    parts = field.split(",")
    for part in parts:
        part = part.strip()
        if not part:
            continue
        if "/" in part:
            rng, step_s = part.split("/", 1)
            step = int(step_s)
            if rng == "*":
                add_range(min_v, max_v, step)
            elif "-" in rng:
                a, b = rng.split("-", 1)
                add_range(int(a), int(b), step)
            else:
                # å•å€¼å¸¦æ­¥è¿›ç­‰ä»·äºè¯¥å€¼
                values.add(int(rng))
        elif "-" in part:
            a, b = part.split("-", 1)
            add_range(int(a), int(b))
        else:
            values.add(int(part))
    # è¿‡æ»¤è¶Šç•Œ
    return {v for v in values if min_v <= v <= max_v}


def _cron_matches(now: datetime.datetime, expr: str) -> bool:
    """åˆ¤æ–­å½“å‰æ—¶é—´æ˜¯å¦åŒ¹é…5æ®µ cron: m h dom mon dow (æ ‡å‡†cronè¯­ä¹‰)"""
    try:
        fields = expr.split()
        if len(fields) != 5:
            return False
        m_set = _parse_cron_field(fields[0], 0, 59)
        h_set = _parse_cron_field(fields[1], 0, 23)
        dom_set = _parse_cron_field(fields[2], 1, 31)
        mon_set = _parse_cron_field(fields[3], 1, 12)
        dow_set = _parse_cron_field(fields[4], 0, 6)  # 0=å‘¨æ—¥ï¼ˆcronè¯­ä¹‰ï¼‰

        # Python: Monday=0..Sunday=6
        cron_dow = (now.weekday() + 1) % 7  # Monday(0)->1, ..., Sunday(6)->0

        dom_match = now.day in dom_set
        dow_match = cron_dow in dow_set

        # æ ‡å‡†cronè¯­ä¹‰ï¼šday-of-month ä¸ day-of-week ä¹‹é—´æ˜¯ OR å…³ç³»
        if dom_set != set(range(1, 32)) and dow_set != set(range(0, 7)):
            day_ok = dom_match or dow_match
        else:
            day_ok = dom_match and dow_match

        return (
            (now.minute in m_set)
            and (now.hour in h_set)
            and (now.month in mon_set)
            and day_ok
        )
    except Exception:
        return False


def get_next_cron_time(
    expr: str,
    from_dt: datetime.datetime | None = None,
    max_minutes: int = 365 * 24 * 60,
):
    """ä¼°ç®—ä¸‹æ¬¡åŒ¹é…æ—¶é—´ï¼ˆæœ¬åœ°æ—¶åŒºï¼‰ã€‚æŒ‰åˆ†é’Ÿç²’åº¦å‘å‰æœç´¢ï¼Œæœ€å¤šä¸€å¹´ã€‚
    è¿”å› datetime æˆ– Noneã€‚"""
    try:
        base = from_dt or now_bj()
        # ä»ä¸‹ä¸€åˆ†é’Ÿå¼€å§‹æ‰¾ï¼Œé¿å…å½“å‰åˆ†é’Ÿé‡å¤
        start = base.replace(second=0, microsecond=0) + datetime.timedelta(minutes=1)
        for i in range(max_minutes):
            t = start + datetime.timedelta(minutes=i)
            if _cron_matches(t, expr):
                return t
    except Exception:
        pass
    return None


async def _run_standard_backup_via_client():
    """
    æ— æ¶ˆæ¯ä¸Šä¸‹æ–‡çš„æ ‡å‡†å¤‡ä»½ï¼šæ‰“åŒ… data+pluginsï¼ˆé»˜è®¤æ’é™¤ sessionï¼‰ï¼Œ
    å¦‚é…ç½®å…è®¸ï¼ˆupload_sessions=Trueï¼‰åˆ™åŒæ—¶ç”Ÿæˆ sessions åŒ…ã€‚
    ä¸Šä¼ é€»è¾‘ï¼šè‹¥å­˜åœ¨ç›®æ ‡IDä¸”>1ï¼Œå…ˆä¸Šä¼ åˆ°æ”¶è—å¤¹å†è½¬å‘ï¼Œä»¥èŠ‚çœé‡å¤ä¸Šä¼ ã€‚
    """
    client = bot
    program_dir = get_program_dir()
    data_dir = os.path.join(program_dir, "data")
    plugins_dir = os.path.join(program_dir, "plugins")
    # æ¸…ç† data/ ä¸‹çš„å†å²é…ç½®å¿«ç…§ï¼Œä»…ä¿ç•™æœ€æ–°ä¸€ä»½
    _prune_config_backups(data_dir)
    now_str = now_bj().strftime("%Y%m%d_%H%M%S")

    tmpdir = tempfile.gettempdir()
    backup_path = os.path.join(tmpdir, f"pagermaid_backup_{now_str}.tar.gz")
    sessions_path = os.path.join(tmpdir, f"pagermaid_sessions_{now_str}.tar.gz")

    # æ˜¯å¦ä¸Šä¼  sessions ç”±é…ç½®å†³å®šï¼ˆé»˜è®¤ Falseï¼‰
    cfg = load_config()
    upload_sessions = bool(cfg.get("upload_sessions", False))

    try:
        # åˆ›å»ºä¸»å¤‡ä»½ï¼ˆæ’é™¤ session æ–‡ä»¶ï¼‰
        create_data_plugins_backup(
            backup_path, program_dir=program_dir, exclude_session=True, compresslevel=5
        )

        # å¦‚éœ€ä¸Šä¼  sessionï¼Œåˆ™å¦å¤–åˆ›å»º sessions åŒ…ï¼ˆä½†è‹¥é…ç½®ç¦æ­¢ï¼Œåˆ™è·³è¿‡ï¼‰
        sessions_created = None
        if upload_sessions:
            sessions_created = create_sessions_archive(
                sessions_path, program_dir=program_dir
            )

        caption = (
            f"ğŸ“¦ **Pagermaidå®šæ—¶æ ‡å‡†å¤‡ä»½**\n\n"
            f"â€¢ åˆ›å»ºæ—¶é—´: {now_bj().strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"â€¢ åŒ…å«: data (ä¸å« session) + plugins\n"
            f"â€¢ è§¦å‘: cron å®šæ—¶ä»»åŠ¡"
        )

        targets = get_target_chat_ids()
        if targets:
            # å¤šç›®æ ‡ä¼˜åŒ–ï¼šå•ç›®æ ‡ç›´æ¥ä¸Šä¼ ï¼Œå¤šç›®æ ‡å…ˆä¸Šä¼ åˆ°æ”¶è—å¤¹å†è½¬å‘
            if len(targets) == 1:
                await client.send_file(int(targets[0]), backup_path, caption=caption)
                if sessions_created:
                    await client.send_file(
                        int(targets[0]),
                        sessions_created,
                        caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦–å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                    )
            else:
                # ä¸Šä¼ åˆ°æ”¶è—å¤¹
                sent_msg = await client.send_file("me", backup_path, caption=caption)
                for tgt in targets:
                    try:
                        await client.forward_messages(int(tgt), sent_msg, "me")
                    except Exception:
                        # è‹¥è½¬å‘å¤±è´¥åˆ™é€€å›ç›´æ¥ä¸Šä¼ 
                        await client.send_file(int(tgt), backup_path, caption=caption)
                # sessions å¦‚æœç”Ÿæˆäº†ä¹ŸåŒæ ·å¤„ç†
                if sessions_created:
                    sent_s = await client.send_file(
                        "me",
                        sessions_created,
                        caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                    )
                    for tgt in targets:
                        try:
                            await client.forward_messages(int(tgt), sent_s, "me")
                        except Exception:
                            await client.send_file(
                                int(tgt),
                                sessions_created,
                                caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                            )
        else:
            # æ— ç›®æ ‡åˆ™å‘é€åˆ°æ”¶è—å¤¹
            await client.send_file("me", backup_path, caption=caption)
            if sessions_created:
                await client.send_file(
                    "me",
                    sessions_created,
                    caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(backup_path):
                os.remove(backup_path)
        except Exception:
            pass
        try:
            if os.path.exists(sessions_path):
                os.remove(sessions_path)
        except Exception:
            pass


async def _cron_loop():
    expr = get_cron_expr()
    if not expr:
        # æœªé…ç½®
        return
    now = now_bj()
    if not _cron_matches(now, expr):
        return
    await _run_standard_backup_via_client()
    # è®°å½•æœ€è¿‘ä¸€æ¬¡è§¦å‘æ—¶é—´
    set_cron_last_run(now.strftime("%Y-%m-%d %H:%M:%S"))


@Hook.load_success()
async def _restart_cron_task():
    """åœ¨æ’ä»¶åŠ è½½å®Œæˆåæ·»åŠ å®šæ—¶ä»»åŠ¡"""
    expr = get_cron_expr()
    if expr and not scheduler.get_job("bf_cron_task"):
        scheduler.add_job(
            _cron_loop,
            "cron",
            minute="*",
            id="bf_cron_task",
            name="bf_cron_task",
        )
    elif not expr and scheduler.get_job("bf_cron_task"):
        # å¦‚æœæ²¡æœ‰é…ç½®åˆ™ç§»é™¤ä»»åŠ¡
        scheduler.remove_job("bf_cron_task")


# ç›®æ ‡èŠå¤©IDç®¡ç†ï¼ˆæ”¯æŒå¤šç›®æ ‡ï¼‰
def get_target_chat_ids():
    cfg = load_config()
    ids = []
    # å‘åå…¼å®¹æ—§å­—æ®µ
    if "target_chat_ids" in cfg and isinstance(cfg["target_chat_ids"], list):
        ids = cfg["target_chat_ids"]
    elif "target_chat_id" in cfg and cfg["target_chat_id"]:
        ids = [cfg["target_chat_id"]]
        # è¿ç§»ä¸ºæ–°å­—æ®µ
        cfg["target_chat_ids"] = ids
        cfg.pop("target_chat_id", None)
        save_config(cfg)
    # è¿‡æ»¤ç©ºç™½
    ids = [str(i).strip() for i in ids if str(i).strip()]
    # å»é‡ä¿æŒé¡ºåº
    seen = set()
    uniq = []
    for i in ids:
        if i not in seen:
            uniq.append(i)
            seen.add(i)
    return uniq


def set_target_chat_ids(new_ids):
    cfg = load_config()
    cfg["target_chat_ids"] = new_ids
    save_config(cfg)


def add_target_chat_ids(ids_to_add):
    exist = get_target_chat_ids()
    for x in ids_to_add:
        s = str(x).strip()
        if s and s not in exist:
            exist.append(s)
    set_target_chat_ids(exist)
    return exist


def remove_target_chat_id(id_to_remove):
    exist = get_target_chat_ids()
    if id_to_remove == "all":
        set_target_chat_ids([])
        return []
    exist = [i for i in exist if i != str(id_to_remove).strip()]
    set_target_chat_ids(exist)
    return exist


def create_tar_gz(
    source_dirs,
    output_filename,
    exclude_dirs=None,
    exclude_exts=None,
    max_file_size_mb=None,
    compresslevel=5,
):
    """
    åˆ›å»º tar.gz å‹ç¼©åŒ…ï¼Œæ”¯æŒæ’é™¤ç›®å½•/åç¼€/å¤§æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨å¯è°ƒå‹ç¼©çº§åˆ«ã€‚

    exclude_dirs: ç›®å½•åé»‘åå•ï¼ˆå‘½ä¸­åˆ™æ•´ç›®å½•è·³è¿‡ï¼‰ï¼Œå¦‚ ['.git', '__pycache__']
    exclude_exts: æ–‡ä»¶åç¼€é»‘åå•ï¼ˆå«ç‚¹ï¼‰ï¼Œå¦‚ ['.log', '.zip']
    max_file_size_mb: è·³è¿‡å¤§äºæ­¤å¤§å°çš„å•æ–‡ä»¶ï¼ˆå•ä½MBï¼‰ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
    compresslevel: gzipå‹ç¼©ç­‰çº§ï¼Œ1(å¿«/å¤§) - 9(æ…¢/å°)ï¼Œé»˜è®¤5æŠ˜ä¸­
    """
    exclude_dirs = set(exclude_dirs or [])
    exclude_exts = set(exclude_exts or [])
    size_limit = (max_file_size_mb * 1024 * 1024) if max_file_size_mb else None

    # Python 3.8+ æ”¯æŒ compresslevel å‚æ•°
    with tarfile.open(output_filename, "w:gz", compresslevel=compresslevel) as tar:
        for source_dir in source_dirs:
            if not os.path.exists(source_dir):
                raise FileNotFoundError(f"{source_dir} ä¸å­˜åœ¨")

            base_name = os.path.basename(source_dir.rstrip(os.sep))

            # å¦‚æœæ˜¯å•ä¸ªæ–‡ä»¶ï¼Œç›´æ¥æ·»åŠ 
            if os.path.isfile(source_dir):
                fname = os.path.basename(source_dir)
                _, ext = os.path.splitext(fname)
                if ext in exclude_exts:
                    continue
                if size_limit is not None:
                    try:
                        if os.path.getsize(source_dir) > size_limit:
                            continue
                    except Exception:
                        continue
                arcname = os.path.join("pagermaid_backup", base_name)
                tar.add(source_dir, arcname=arcname)
                continue

            # ç›®å½•åˆ™é€’å½’éå†
            for root, dirs, files in os.walk(source_dir):
                # è¿‡æ»¤ç›®å½•
                dirs[:] = [d for d in dirs if d not in exclude_dirs]

                for fname in files:
                    fpath = os.path.join(root, fname)
                    # è¿‡æ»¤åç¼€
                    _, ext = os.path.splitext(fname)
                    if ext in exclude_exts:
                        continue
                    # è¿‡æ»¤å¤§æ–‡ä»¶
                    if size_limit is not None:
                        try:
                            if os.path.getsize(fpath) > size_limit:
                                continue
                        except Exception:
                            continue

                    # å½’æ¡£åï¼špagermaid_backup/<source_dir_name>/<relative_path>
                    rel = os.path.relpath(fpath, source_dir)
                    # ç¡®ä¿ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œé˜²æ­¢è·¯å¾„ç©¿è¶Š
                    rel = os.path.normpath(rel)
                    if os.path.isabs(rel) or rel.startswith(".."):
                        continue  # è·³è¿‡å±é™©è·¯å¾„
                    arcname = os.path.join("pagermaid_backup", base_name, rel)
                    tar.add(fpath, arcname=arcname)


def _gather_session_files(data_dir: str):
    """è¿”å› data ç›®å½•ä¸‹æ‰€æœ‰ session ç›¸å…³æ–‡ä»¶çš„ç»å¯¹è·¯å¾„åˆ—è¡¨"""
    sessions = []
    if not os.path.isdir(data_dir):
        return sessions
    for root, dirs, files in os.walk(data_dir):
        for f in files:
            if f.endswith(".session") or f.endswith(".session-journal"):
                sessions.append(os.path.join(root, f))
    return sessions


def create_data_plugins_backup(
    output_filename: str,
    program_dir: str | None = None,
    exclude_session: bool = True,
    compresslevel: int = 5,
    archive_root: str = "pagermaid_backup",
):
    """
    åªæ‰“åŒ… program_dir ä¸‹çš„ data ä¸ pluginsï¼ˆå¯é€‰æ‹©æ’é™¤ session æ–‡ä»¶ï¼‰ã€‚
    - output_filename: å®Œæ•´è·¯å¾„
    - exclude_session: True åˆ™è·³è¿‡ *.session / *.session-journal
    - archive_root: å‹ç¼©åŒ…å†…çš„æ ¹ç›®å½•åï¼ˆé»˜è®¤ pagermaid_backupï¼‰
    """
    program_dir = program_dir or get_program_dir()
    data_dir = os.path.join(program_dir, "data")
    plugins_dir = os.path.join(program_dir, "plugins")

    os.makedirs(os.path.dirname(output_filename), exist_ok=True)

    # ä½¿ç”¨ explicit walk ä»¥ä¾¿ç²¾ç¡®æ§åˆ¶å“ªäº›æ–‡ä»¶ä¼šè¢«åŠ å…¥
    with tarfile.open(output_filename, "w:gz", compresslevel=compresslevel) as tar:

        def _add_tree(src_dir):
            if not os.path.isdir(src_dir):
                return
            for root, dirs, files in os.walk(src_dir):
                # æ’é™¤ __pycache__ ç­‰ä¸´æ—¶ç›®å½•
                dirs[:] = [d for d in dirs if d != "__pycache__"]
                for fname in files:
                    if exclude_session and (
                        fname.endswith(".session") or fname.endswith(".session-journal")
                    ):
                        continue
                    full = os.path.join(root, fname)
                    # å½’æ¡£å†…è·¯å¾„ï¼šä»¥ program_dir ä¸ºåŸºå‡† => pagermaid_backup/<relative_path>
                    rel = os.path.relpath(full, program_dir)
                    # é˜²æ­¢è·¯å¾„ç©¿è¶Šä¸ç»å¯¹è·¯å¾„ï¼šrel ä¸åº”ä»¥ .. å¼€å¤´
                    if rel.startswith(".."):
                        continue
                    arcname = os.path.join(archive_root, rel) if archive_root else rel
                    tar.add(full, arcname=arcname)

        # å…ˆæ·»åŠ  pluginsï¼Œå†æ·»åŠ  dataï¼ˆé¡ºåºæ— å…³ï¼‰
        _add_tree(plugins_dir)
        _add_tree(data_dir)


def create_sessions_archive(output_filename: str, program_dir: str | None = None):
    """
    å°† data ä¸‹çš„ session æ–‡ä»¶ï¼ˆ*.session, *.session-journalï¼‰æ‰“åŒ…ä¸ºå•ç‹¬çš„ archiveã€‚
    è‹¥ä¸å­˜åœ¨ session æ–‡ä»¶ï¼Œè¿”å› Noneï¼›å¦åˆ™è¿”å› output_filenameã€‚
    """
    program_dir = program_dir or get_program_dir()
    data_dir = os.path.join(program_dir, "data")
    sessions = _gather_session_files(data_dir)
    if not sessions:
        return None

    os.makedirs(os.path.dirname(output_filename), exist_ok=True)
    with tarfile.open(output_filename, "w:gz") as tar:
        for fpath in sessions:
            # arcname æ”¾åˆ° sessions/<relative_path_from_data>
            rel = os.path.relpath(fpath, data_dir)
            if rel.startswith(".."):
                # é˜²æŠ¤ï¼šä¸æ¥å— data ç›®å½•å¤–çš„æ–‡ä»¶
                continue
            arcname = os.path.join("sessions", rel)
            tar.add(fpath, arcname=arcname)
    return output_filename


def _prune_config_backups(data_dir: str, keep_count: int = 1):
    """æ¸…ç† data/ ä¸‹çš„å†å²é…ç½®å¿«ç…§ï¼Œä»…ä¿ç•™æœ€æ–°ä¸€ä»½"""
    try:
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„æ¸…ç†é€»è¾‘ï¼Œæ¯”å¦‚åˆ é™¤æ—§çš„é…ç½®å¤‡ä»½æ–‡ä»¶
        # ç›®å‰ä¸ºç©ºå®ç°ï¼Œå¯æ ¹æ®å®é™…éœ€è¦æ·»åŠ 
        pass
    except Exception:
        pass


def delete_specific_files_from_backup(backup_file, temp_dir, files_to_delete):
    with tarfile.open(backup_file, "r:gz") as tar:
        tar.extractall(path=temp_dir)
    for root, dirs, files in os.walk(temp_dir):
        for file_name in files:
            if file_name in files_to_delete:
                file_path = os.path.join(root, file_name)
                os.remove(file_path)
    new_backup_file = backup_file.replace(".tar.gz", "_modified.tar.gz")
    with tarfile.open(new_backup_file, "w:gz") as tar:
        tar.add(temp_dir, arcname="pagermaid_backup")
    return new_backup_file


def safe_extract(tar, path="."):
    """ä¸¥æ ¼çš„å®‰å…¨è§£å‹å‡½æ•°ï¼Œé˜²æ­¢è·¯å¾„ç©¿è¶Šæ”»å‡»"""
    abs_path = os.path.abspath(path)

    for member in tar.getmembers():
        # è§„èŒƒåŒ–è·¯å¾„
        member_path = os.path.normpath(member.name)

        # æ£€æŸ¥ç»å¯¹è·¯å¾„
        if os.path.isabs(member_path):
            raise Exception(f"æ£€æµ‹åˆ°ç»å¯¹è·¯å¾„ï¼Œæ‹’ç»è§£å‹: {member.name}")

        # æ£€æŸ¥è·¯å¾„ç©¿è¶Š
        full_path = os.path.abspath(os.path.join(path, member_path))
        if not full_path.startswith(abs_path + os.sep) and full_path != abs_path:
            raise Exception(f"è·¯å¾„ç©¿è¶Šæ£€æµ‹åˆ°ï¼Œç»ˆæ­¢æ¢å¤: {member.name}")

        # æ£€æŸ¥å…è®¸çš„ç›®å½•ï¼ˆç™½åå•ï¼‰
        allowed_dirs = ["plugins", "data", "pagermaid_backup"]
        path_parts = member_path.split(os.sep)
        if path_parts and path_parts[0] not in allowed_dirs:
            raise Exception(f"ä¸å…è®¸çš„ç›®å½•è·¯å¾„: {member.name}")

    # æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œæ‰§è¡Œè§£å‹
    tar.extractall(path)


def un_tar_gz(filename, dirs):
    """å®‰å…¨è§£å‹ .tar.gz åˆ°æŒ‡å®šç›®å½•ï¼Œé¿å…è·¯å¾„ç©¿è¶Š"""
    try:
        with tarfile.open(filename, "r:gz") as tar:
            safe_extract(tar, dirs)
        return True
    except Exception as e:
        print(f"è§£å‹å¤±è´¥: {e}")
        return False


def sanitize_filename(filename):
    """æ¸…ç†æ–‡ä»¶åï¼Œç¡®ä¿å®‰å…¨"""
    # ç§»é™¤æˆ–æ›¿æ¢å±é™©å­—ç¬¦
    safe_name = re.sub(r"[^a-zA-Z0-9_.-]", "_", filename)
    # é™åˆ¶é•¿åº¦
    if len(safe_name) > 100:
        safe_name = safe_name[:100]
    return safe_name


def generate_smart_package_name(backup_type="backup"):
    """AIæ™ºèƒ½ç”ŸæˆåŒ…å"""
    # è·å–å½“å‰æ—¶é—´ä¿¡æ¯
    now = now_bj()
    timestamp = now.strftime("%Y%m%d_%H%M%S")

    # æ ¹æ®å¤‡ä»½ç±»å‹ç”Ÿæˆå‰ç¼€
    if backup_type == "plugins":
        prefix = "bf_p"
    elif backup_type == "data":
        prefix = "bf_d"
    elif backup_type == "full":
        prefix = "bf_all"
    else:
        prefix = "bf"

    # ç”Ÿæˆå®‰å…¨çš„éšæœºID
    random_id = secrets.token_hex(4)  # 8å­—ç¬¦éšæœºID

    # ç»„åˆåŒ…åå¹¶æ¸…ç†
    package_name = f"{prefix}_{timestamp}_{random_id}.tar.gz"
    package_name = sanitize_filename(package_name)

    return package_name


def create_secure_temp_file(suffix=".tar.gz"):
    """åˆ›å»ºå®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶"""
    program_dir = get_program_dir()
    temp_dir = os.path.join(program_dir, "data", "temp")
    os.makedirs(temp_dir, exist_ok=True)

    # è®¾ç½®ç›®å½•æƒé™ï¼ˆä»…æ‰€æœ‰è€…å¯è®¿é—®ï¼‰
    try:
        os.chmod(temp_dir, 0o700)
    except Exception:
        pass  # Windowså¯èƒ½ä¸æ”¯æŒ

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    fd, temp_path = tempfile.mkstemp(suffix=suffix, dir=temp_dir)
    os.close(fd)  # å…³é—­æ–‡ä»¶æè¿°ç¬¦ï¼Œä½†ä¿ç•™æ–‡ä»¶
    return temp_path


def check_backup_size(file_path, max_size_mb=100):
    """æ£€æŸ¥å¤‡ä»½æ–‡ä»¶å¤§å°"""
    if os.path.exists(file_path):
        size_mb = os.path.getsize(file_path) / 1024 / 1024
        if size_mb > max_size_mb:
            return False, f"å¤‡ä»½æ–‡ä»¶è¿‡å¤§: {size_mb:.1f}MB > {max_size_mb}MB"
        return True, f"æ–‡ä»¶å¤§å°: {size_mb:.1f}MB"
    return False, "æ–‡ä»¶ä¸å­˜åœ¨"


def create_backup_info(backup_type, file_list=None):
    """åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®ä¿¡æ¯"""
    import sys

    return {
        "version": "1.0",
        "backup_type": backup_type,
        "created_at": now_bj().isoformat(),
        "created_by": "bf_plugin",
        "file_count": len(file_list) if file_list else 0,
        "files": file_list or [],
        "platform": os.name,
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        "backup_format": "tar.gz",
        "compression_level": 5,
        "exclude_sessions": True,
        "security_validated": True,
    }


def add_backup_info_to_archive(tar_path, backup_info):
    """å‘å¤‡ä»½æ–‡ä»¶ä¸­æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯"""
    try:
        # åˆ›å»ºä¸´æ—¶ä¿¡æ¯æ–‡ä»¶
        temp_info_file = create_secure_temp_file(".json")
        with open(temp_info_file, "w", encoding="utf-8") as f:
            json.dump(backup_info, f, ensure_ascii=False, indent=2)

        # æ·»åŠ åˆ°å­˜æ¡£
        with tarfile.open(tar_path, "a:gz") as tar:
            tar.add(temp_info_file, arcname="backup_info.json")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_info_file)
        return True
    except Exception as e:
        print(f"æ·»åŠ å¤‡ä»½ä¿¡æ¯å¤±è´¥: {e}")
        return False


def read_backup_info(tar_path):
    """ä»å¤‡ä»½æ–‡ä»¶ä¸­è¯»å–å…ƒæ•°æ®ä¿¡æ¯"""
    try:
        with tarfile.open(tar_path, "r:gz") as tar:
            try:
                info_member = tar.getmember("backup_info.json")
                info_file = tar.extractfile(info_member)
                if info_file:
                    return json.loads(info_file.read().decode("utf-8"))
            except KeyError:
                # æ—§ç‰ˆæœ¬å¤‡ä»½æ²¡æœ‰å…ƒæ•°æ®
                return None
    except Exception as e:
        print(f"è¯»å–å¤‡ä»½ä¿¡æ¯å¤±è´¥: {e}")
    return None


# bf å¤‡ä»½å‘½ä»¤
@listener(command="bf", description="å¤‡ä»½ä¸»å‘½ä»¤ï¼Œæ”¯æŒå¤šç§å¤‡ä»½æ¨¡å¼", need_admin=True)
async def bf(message: Message):
    param = message.parameter
    program_dir = get_program_dir()

    if param and param[0] in ["help", "å¸®åŠ©"]:
        help_text = (
            "ğŸ”§ å¤‡ä»½/æ¢å¤ å¿«é€ŸæŒ‡å—\n\n"
            "å¸¸ç”¨ï¼š\n"
            "â€¢ å¸®åŠ©ï¼š`bf help`\n"
            "â€¢ æ ‡å‡†ï¼š`bf`\n"
            "â€¢ å…¨é‡ï¼š`bf all [slim|fast]`\n"
            "â€¢ æ’ä»¶ï¼š`bf p`\n"
            "â€¢ ç›®æ ‡ï¼š`bf set <ID...>` / `bf del <ID|all>`\n"
            "â€¢ æ¢å¤ï¼š`hf`ï¼ˆå¯åœ¨å¤‡ä»½ä¸Šå›å¤åæ‰§è¡Œï¼‰\n"
            "â€¢ å®šæ—¶ï¼š`bf cron`\n\n"
            "æç¤ºï¼šæ‰§è¡Œå­å‘½ä»¤ä¼šæ˜¾ç¤ºå¯¹åº”è¯´æ˜ï¼ˆå¦‚ `bf cron` æˆ– `<æŒ‡ä»¤å> help`ï¼‰ã€‚"
        )
        await message.edit(help_text)
        return

    if param and param[0] == "set":
        # bf set <id...>
        if len(param) < 2 or param[1] in ["help", "-h", "--help", "?"]:
            set_help = (
                "ğŸ¯ è®¾ç½®ç›®æ ‡èŠå¤©\n\n"
                "ç”¨æ³•ï¼š\n"
                "â€¢ `bf set <ID...>`\n"
                "  - å¯ç©ºæ ¼æˆ–é€—å·åˆ†éš”å¤šä¸ªID\n\n"
                "ç¤ºä¾‹ï¼š\n"
                "â€¢ `bf set 123456789 987654321`\n"
                "â€¢ `bf set 123456789,987654321`\n\n"
                "æç¤ºï¼šè®¾ç½®åï¼Œå¤‡ä»½ä¼šå‘é€åˆ°è¿™äº›ç›®æ ‡ï¼›æœªè®¾ç½®æ—¶å‘é€åˆ°æ”¶è—å¤¹ã€‚"
            )
            await message.edit(set_help)
            return

        try:
            raw = " ".join(param[1:])
            # æ”¯æŒç©ºæ ¼/é€—å·åˆ†éš”
            parts = []
            for seg in raw.replace(",", " ").split():
                if seg.strip():
                    parts.append(seg.strip())
            # æ ¡éªŒï¼šä»…å…è®¸çº¯æ•°å­—æˆ–ä»¥ '-' å¼€å¤´çš„æ•°å­—ï¼ˆèŠå¤©ID/é¢‘é“IDï¼‰ï¼Œä¸æ¥å— @username
            import re

            valid = []
            for seg in parts:
                if re.fullmatch(r"-?\d+", seg):
                    valid.append(seg)
                else:
                    await message.edit(
                        f"æ— æ•ˆçš„èŠå¤©ID: {seg} \nä»…æ”¯æŒæ•°å­—IDï¼Œä¾‹å¦‚ 123456 æˆ– -1001234567890"
                    )
                    return
            if not valid:
                await message.edit("èŠå¤©IDä¸èƒ½ä¸ºç©º")
                return
            new_list = add_target_chat_ids(valid)
            await message.edit(
                f"ç›®æ ‡èŠå¤©IDå·²æ›´æ–°ï¼š{', '.join(new_list) if new_list else 'ï¼ˆå·²æ¸…ç©ºï¼‰'}"
            )
            return
        except Exception as e:
            await message.edit(f"è®¾ç½®å¤±è´¥ï¼š{str(e)}")
            return

    if param and param[0] == "del":
        # bf del <id|all>
        if len(param) < 2 or param[1] in ["help", "-h", "--help", "?"]:
            del_help = (
                "ğŸ§¹ åˆ é™¤ç›®æ ‡èŠå¤©\n\n"
                "ç”¨æ³•ï¼š\n"
                "â€¢ åˆ é™¤å•ä¸ªï¼š`bf del <ID>`\n"
                "â€¢ æ¸…ç©ºå…¨éƒ¨ï¼š`bf del all`\n\n"
                "ç¤ºä¾‹ï¼š\n"
                "â€¢ `bf del 123456789`\n"
                "â€¢ `bf del all`\n"
            )
            await message.edit(del_help)
            return
        target = param[1]
        try:
            new_list = remove_target_chat_id(target)
            if target == "all":
                await message.edit("å·²æ¸…ç©ºå…¨éƒ¨ç›®æ ‡èŠå¤©ID")
            else:
                await message.edit(
                    f"å·²åˆ é™¤ï¼š{target}ï¼Œå½“å‰ç›®æ ‡åˆ—è¡¨ï¼š{', '.join(new_list) if new_list else 'ï¼ˆç©ºï¼‰'}"
                )
            return
        except Exception as e:
            await message.edit(f"åˆ é™¤å¤±è´¥ï¼š{str(e)}")
            return

    # bf cron - ç®¡ç†å®šæ—¶ä»»åŠ¡ï¼ˆå›½é™…æ ‡å‡†5æ®µcronï¼‰
    if param and param[0] == "cron":
        # ç”¨æ³•ï¼š
        # bf cron show
        # bf cron off
        # bf cron * * * * *
        if len(param) == 1:
            cur = get_cron_expr()
            last = get_cron_last_run()
            nxt = None
            if cur:
                nxt_dt = get_next_cron_time(cur)
                nxt = nxt_dt.strftime("%Y-%m-%d %H:%M") if nxt_dt else "â€”"
            cron_help = (
                "â±ï¸ Cron å®šæ—¶å¤‡ä»½\n\n"
                "ç”¨æ³•ï¼š\n"
                "â€¢ æŸ¥çœ‹å½“å‰ï¼š`bf cron show`\n"
                "â€¢ å…³é—­å®šæ—¶ï¼š`bf cron off`\n"
                "â€¢ è®¾ç½®å®šæ—¶ï¼š`bf cron <m h dom mon dow>`ï¼ˆ5 æ®µå›½é™…æ ‡å‡†ï¼‰\n\n"
                f"å½“å‰è®¾ç½®ï¼š{cur if cur else 'æœªè®¾ç½®'}\n"
                f"æœ€è¿‘ä¸€æ¬¡è§¦å‘ï¼š{last if last else 'â€”'}\n"
                f"ä¸‹æ¬¡é¢„è®¡è§¦å‘ï¼š{nxt if nxt != 'â€”' else 'â€”'}\n\n"
                "è¯­æ³•è¯´æ˜ï¼š\n"
                "â€¢ * ä»»æ„å€¼  â€¢ a-b èŒƒå›´  â€¢ a,b åˆ—è¡¨  â€¢ */n æ­¥è¿›  â€¢ a-b/n ç»„åˆ\n"
                "â€¢ æ˜ŸæœŸå–å€¼ 0-6ï¼ˆ0=å‘¨æ—¥ï¼‰\n\n"
                "å¸¸ç”¨ç¤ºä¾‹ï¼š\n"
                "â€¢ æ¯åˆ†é’Ÿï¼š`bf cron * * * * *`\n"
                "â€¢ æ¯ 5 åˆ†é’Ÿï¼š`bf cron */5 * * * *`\n"
                "â€¢ æ¯å¤© 03:30ï¼š`bf cron 30 3 * * *`\n"
                "â€¢ å·¥ä½œæ—¥ 02:00ï¼š`bf cron 0 2 * * 1-5`\n"
                "â€¢ æ¯æœˆ 1 æ—¥ 00:10ï¼š`bf cron 10 0 1 * *`\n"
                "â€¢ æ¯å‘¨æ—¥ 23:50ï¼š`bf cron 50 23 * * 0`\n\n"
                "æç¤ºï¼š\n"
                "â€¢ å®šæ—¶ä»»åŠ¡è§¦å‘æ ‡å‡†å¤‡ä»½ï¼ˆç­‰åŒ `bf`ï¼‰\n"
                "â€¢ åŒä¸€åˆ†é’Ÿåªä¼šè§¦å‘ä¸€æ¬¡ï¼›æ—¶é—´ä»¥æœ¬åœ°æ—¶åŒºè®¡ç®—\n"
                "â€¢ å¦‚å·²è®¾ç½®ç›®æ ‡èŠå¤©ï¼ˆ`bf set ...`ï¼‰ï¼Œå¤‡ä»½å°†å‘é€åˆ°ç›®æ ‡ï¼›å¦åˆ™å‘é€åˆ°æ”¶è—å¤¹\n"
            )
            await message.edit(cron_help)
            return
        sub = " ".join(param[1:]).strip()
        if sub.lower() == "show":
            cur = get_cron_expr()
            last = get_cron_last_run()
            nxt = None
            if cur:
                nxt_dt = get_next_cron_time(cur)
                nxt = nxt_dt.strftime("%Y-%m-%d %H:%M") if nxt_dt else "â€”"
            await message.edit(
                f"å½“å‰å®šæ—¶ï¼š{cur if cur else 'æœªè®¾ç½®'}\næœ€è¿‘ä¸€æ¬¡è§¦å‘ï¼š{last if last else 'â€”'}\nä¸‹æ¬¡é¢„è®¡è§¦å‘ï¼š{nxt if cur else 'â€”'}"
            )
            return
        if sub.lower() == "off":
            set_cron_expr(None)
            await _restart_cron_task()
            await message.edit("å·²å…³é—­å®šæ—¶å¤‡ä»½")
            return
        # å…¶ä½™è§†ä¸ºè¡¨è¾¾å¼
        fields = sub.split()
        if len(fields) != 5:
            await message.edit("æ— æ•ˆçš„è¡¨è¾¾å¼ï¼šå¿…é¡»ä¸º5æ®µï¼Œå¦‚ï¼šbf cron * * * * *")
            return
        # åŸºç¡€åˆæ³•æ€§æ ¡éªŒ
        try:
            # ç®€å•è°ƒç”¨è§£æé¿å…å¼‚å¸¸
            _ = _parse_cron_field(fields[0], 0, 59)
            _ = _parse_cron_field(fields[1], 0, 23)
            _ = _parse_cron_field(fields[2], 1, 31)
            _ = _parse_cron_field(fields[3], 1, 12)
            _ = _parse_cron_field(fields[4], 0, 6)
        except Exception as e:
            await message.edit(f"è¡¨è¾¾å¼è§£æå¤±è´¥ï¼š{str(e)}")
            return
        set_cron_expr(sub)
        await _restart_cron_task()
        nxt_dt = get_next_cron_time(sub)
        nxt = nxt_dt.strftime("%Y-%m-%d %H:%M") if nxt_dt else "â€”"
        await message.edit(
            f"âœ… å·²è®¾ç½®å®šæ—¶å¤‡ä»½ï¼š`{sub}`\nä¸‹æ¬¡é¢„è®¡è§¦å‘ï¼š{nxt}\næç¤ºï¼šå®šæ—¶ä»»åŠ¡å°†äºåŒ¹é…åˆ†é’Ÿè§¦å‘ï¼Œæ–‡ä»¶å‘é€åˆ°å·²é…ç½®ç›®æ ‡æˆ–æ”¶è—å¤¹ã€‚"
        )
        return

    # bf all - å®Œæ•´ç¨‹åºå¤‡ä»½
    if param and param[0] == "all":
        try:
            await message.edit("ğŸ”„ æ­£åœ¨åˆ›å»ºå®Œæ•´ç¨‹åºå¤‡ä»½...")
            # ç”Ÿæˆæ™ºèƒ½åŒ…å
            package_name = generate_smart_package_name("full")
            backup_filename = f"{package_name}.tar.gz"
            slim_mode = len(param) > 1 and param[1].lower() in ["slim", "fast"]

            # å¤‡ä»½æ•´ä¸ªç¨‹åºç›®å½•ï¼šæ‰©å±•æ’é™¤è§„åˆ™ï¼Œå¹¶ä½¿ç”¨æ›´å¿«å‹ç¼©ç­‰çº§
            exclude_dirnames = [
                ".git",
                "__pycache__",
                ".pytest_cache",
                "venv",
                "env",
                ".venv",
                "node_modules",
                "cache",
                "caches",
                "logs",
                "log",
                "downloads",
                "download",
                "media",
                ".mypy_cache",
                ".ruff_cache",
            ]
            exclude_exts = [
                ".log",  # æ—¥å¿—æ–‡ä»¶
                # æ³¨æ„ï¼šä¸æ’é™¤ .zip, .tar, .gz ç­‰å‹ç¼©æ–‡ä»¶ï¼Œå› ä¸ºå¯èƒ½æ˜¯é‡è¦çš„å¤‡ä»½æ•°æ®
                # ä¸æ’é™¤åª’ä½“æ–‡ä»¶ï¼Œå› ä¸ºå¯èƒ½æ˜¯ç”¨æˆ·æ•°æ®
            ]

            # ç˜¦èº«æ¨¡å¼ï¼šæ›´æ¿€è¿›çš„ç›®å½•æ’é™¤ä¸æ–‡ä»¶å¤§å°é™åˆ¶ï¼Œå‹ç¼©ç­‰çº§æ›´å¿«
            max_file_size_mb = None
            compress_level = 5
            if slim_mode:
                exclude_dirnames.extend(["dist", "build", ".cache", "tmp", "temp"])
                max_file_size_mb = 20  # è·³è¿‡è¶…è¿‡20MBçš„å¤§æ–‡ä»¶
                compress_level = 3  # æ›´å¿«ä¸€äº›

            include_items = []
            for item in os.listdir(program_dir):
                # ä¿æŒä¸åŸæœ‰é€»è¾‘ä¸€è‡´ï¼šåªè·³è¿‡éšè—æ–‡ä»¶ï¼ˆä»¥ç‚¹å¼€å¤´ï¼‰çš„é¡¶å±‚æ–‡ä»¶
                if item.startswith("."):
                    continue
                include_items.append(os.path.join(program_dir, item))

            create_tar_gz(
                include_items,
                backup_filename,
                exclude_dirs=exclude_dirnames,
                exclude_exts=exclude_exts,
                max_file_size_mb=max_file_size_mb,
                compresslevel=compress_level,
            )

            await message.edit("ğŸ“¤ æ­£åœ¨ä¸Šä¼ å®Œæ•´å¤‡ä»½...")
            import datetime

            caption = (
                f"ğŸ¯ **å®Œæ•´ç¨‹åºå¤‡ä»½{'ï¼ˆç˜¦èº«ï¼‰' if slim_mode else ''}**\n\n"
                f"â€¢ åŒ…å: `{package_name}`\n"
                f"â€¢ åˆ›å»ºæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"â€¢ å¤‡ä»½ç±»å‹: å®Œæ•´ç¨‹åºåŒ…{'ï¼ˆç˜¦èº«ä¸Šä¼ æ›´å¿«ï¼‰' if slim_mode else ''}\n"
                f"â€¢ åŒ…å«: æ‰€æœ‰ç¨‹åºæ–‡ä»¶å’Œé…ç½®"
                f"{'ï¼ˆè·³è¿‡>20MBæ–‡ä»¶ä¸æ›´å¤šç¼“å­˜ç›®å½•ï¼‰' if slim_mode else ''}"
            )

            # æ ¹æ®æ˜¯å¦å­˜åœ¨ç›®æ ‡IDå†³å®šå‘é€ç›®çš„åœ°
            targets = get_target_chat_ids()
            show_progress = len(targets) <= 1

            # è¿›åº¦æ¡ä»…åœ¨å•ç›®æ ‡æ—¶å±•ç¤ºï¼Œé¿å…å¤šæ¬¡åˆ·å±
            progress = {"last": 0}

            def _progress(sent, total):
                if not show_progress:
                    return
                try:
                    if total:
                        pct = int(sent * 100 / total)
                        if pct >= progress["last"] + 10:
                            progress["last"] = pct
                            try:
                                message.client.loop.create_task(
                                    message.edit(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼ å®Œæ•´å¤‡ä»½... {pct}%")
                                )
                            except Exception:
                                pass
                except Exception:
                    pass

            try:
                if targets:
                    for idx, tgt in enumerate(targets, 1):
                        await message.client.send_file(
                            int(tgt),
                            backup_filename,
                            caption=caption,
                            force_document=True,
                            progress_callback=_progress if show_progress else None,
                        )
                else:
                    await message.client.send_file(
                        "me",
                        backup_filename,
                        caption=caption,
                        force_document=True,
                        progress_callback=_progress,
                    )
            except Exception as e:
                raise Exception(f"ä¸Šä¼ å¤±è´¥: {str(e)}")

            os.remove(backup_filename)
            if targets:
                await message.edit(
                    f"âœ… å®Œæ•´å¤‡ä»½å·²å®Œæˆ\n\nğŸ“¦ **åŒ…å:** `{package_name}`\nğŸ¯ **å·²å‘é€åˆ°:** {', '.join(targets)}"
                )
            else:
                await message.edit(
                    f"âœ… å®Œæ•´å¤‡ä»½å·²å®Œæˆ\n\nğŸ“¦ **åŒ…å:** `{package_name}`\nğŸ¯ **å·²ä¿å­˜åˆ°:** æ”¶è—å¤¹"
                )
            return
        except Exception as e:
            if "backup_filename" in locals() and os.path.exists(backup_filename):
                os.remove(backup_filename)
            await message.edit(f"âŒ å®Œæ•´å¤‡ä»½å¤±è´¥: {str(e)}")
            return

    # bf p - ä»…å¤‡ä»½Pythonæ’ä»¶
    if param and param[0] == "p":
        try:
            await message.edit("ğŸ æ­£åœ¨åˆ›å»ºPythonæ’ä»¶å¤‡ä»½...")
            # ç”Ÿæˆæ™ºèƒ½åŒ…å
            package_name = generate_smart_package_name("plugins")
            backup_filename = f"{package_name}.tar.gz"

            plugins_dir = os.path.join(program_dir, "plugins")
            if not os.path.exists(plugins_dir):
                await message.edit("âŒ pluginsç›®å½•ä¸å­˜åœ¨")
                return

            # åˆ›å»ºä¸´æ—¶æ ¹ç›®å½•ï¼Œå¹¶åœ¨å…¶ä¸­åˆ›å»º plugins ç›®å½•ï¼Œä¿è¯æ‰“åŒ…æ ¹ä¸º plugins
            temp_root = os.path.join(program_dir, "_tmp_plugins_py_only")
            temp_plugins_dir = os.path.join(temp_root, "plugins")
            os.makedirs(temp_plugins_dir, exist_ok=True)

            # é€’å½’å¤åˆ¶æ‰€æœ‰ .py æ–‡ä»¶ï¼Œä¿ç•™ç›®å½•ç»“æ„ï¼Œæ’é™¤ __pycache__
            py_count = 0
            for root, dirs, files in os.walk(plugins_dir):
                # è¿‡æ»¤æ— ç”¨ç›®å½•
                dirs[:] = [d for d in dirs if d != "__pycache__"]
                for fname in files:
                    if not fname.endswith(".py"):
                        continue
                    src_path = os.path.join(root, fname)
                    rel_path = os.path.relpath(src_path, plugins_dir)
                    dst_path = os.path.join(temp_plugins_dir, rel_path)
                    os.makedirs(os.path.dirname(dst_path), exist_ok=True)
                    shutil.copy2(src_path, dst_path)
                    py_count += 1

            if py_count == 0:
                shutil.rmtree(temp_root)
                await message.edit("âŒ æœªæ‰¾åˆ°ä»»ä½•Pythonæ’ä»¶æ–‡ä»¶")
                return

            # åªæ‰“åŒ…ä¸´æ—¶æ ¹ä¸‹çš„ plugins ç›®å½•ï¼Œä¿è¯å½’æ¡£æ ¹ç›®å½•åä¸º plugins
            create_tar_gz([temp_plugins_dir], backup_filename)
            shutil.rmtree(temp_root)

            await message.edit("ğŸ“¤ æ­£åœ¨åˆ†äº«æ’ä»¶å¤‡ä»½...")
            import datetime

            caption = f"ğŸ **Pythonæ’ä»¶å¤‡ä»½**\n\nâ€¢ åŒ…å: `{package_name}`\nâ€¢ åˆ›å»ºæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nâ€¢ å¤‡ä»½ç±»å‹: Pythonæ’ä»¶åŒ…\nâ€¢ æ’ä»¶æ•°é‡: {py_count} ä¸ª\nâ€¢ é€‚åˆ: æ’ä»¶åˆ†äº«å’Œè¿ç§»"

            # å®‰å…¨çš„å¤šç›®æ ‡ä¸Šä¼ ï¼šå…ˆä¸Šä¼ åˆ°æ‰€æœ‰ç›®æ ‡ï¼Œå†åˆ é™¤æ–‡ä»¶
            targets = get_target_chat_ids()
            upload_tasks = []

            if targets:
                for tgt in targets:
                    upload_tasks.append(
                        message.client.send_file(
                            int(tgt), backup_filename, caption=caption
                        )
                    )
            else:
                upload_tasks.append(
                    message.client.send_file("me", backup_filename, caption=caption)
                )

            # ç­‰å¾…æ‰€æœ‰ä¸Šä¼ å®Œæˆ
            await asyncio.gather(*upload_tasks)

            # æ‰€æœ‰ä¸Šä¼ å®Œæˆåæ‰åˆ é™¤æ–‡ä»¶
            os.remove(backup_filename)
            if targets:
                await message.edit(
                    f"âœ… æ’ä»¶å¤‡ä»½å·²å®Œæˆ\n\nğŸ“¦ **åŒ…å:** `{package_name}`\nğŸ **æ’ä»¶æ•°é‡:** {py_count} ä¸ª\nğŸ¯ **å·²å‘é€åˆ°:** {', '.join(targets)}"
                )
            else:
                await message.edit(
                    f"âœ… æ’ä»¶å¤‡ä»½å·²å®Œæˆ\n\nğŸ“¦ **åŒ…å:** `{package_name}`\nğŸ **æ’ä»¶æ•°é‡:** {py_count} ä¸ª\nğŸ¯ **å·²ä¿å­˜åˆ°:** æ”¶è—å¤¹"
                )
            return
        except Exception as e:
            if "backup_filename" in locals() and os.path.exists(backup_filename):
                os.remove(backup_filename)
            # æ¸…ç†æ’ä»¶ä¸´æ—¶ç›®å½•ï¼ˆå°½é‡ç§»é™¤æ ¹ç›®å½•ä¸å…¶å­ç›®å½•ï¼‰
            try:
                if "temp_root" in locals() and os.path.exists(temp_root):
                    shutil.rmtree(temp_root)
                elif "temp_plugins_dir" in locals() and os.path.exists(
                    temp_plugins_dir
                ):
                    shutil.rmtree(temp_plugins_dir)
            except Exception:
                pass
            await message.edit(f"âŒ æ’ä»¶å¤‡ä»½å¤±è´¥: {str(e)}")
            return

    if param and param[0] == "to":
        # å…¼å®¹æ—§å‘½ä»¤ï¼šæç¤ºå·²å–æ¶ˆæ­¤å‘½ä»¤ï¼Œæ”¹ç”¨ bf set / bf del
        targets = get_target_chat_ids()
        await message.edit(
            "â„¹ï¸ `bf to` å·²å–æ¶ˆï¼š\n"
            "- ç°åœ¨å¦‚å·²è®¾ç½®ç›®æ ‡èŠå¤©IDï¼Œ`bf`/`bf all`/`bf p` ä¼šé»˜è®¤å‘é€åˆ°æ‰€æœ‰ç›®æ ‡\n"
            "- ä½¿ç”¨ `bf set <ID...>` å¢åŠ ç›®æ ‡ï¼›`bf del <ID|all>` åˆ é™¤ç›®æ ‡\n"
            f"- å½“å‰ç›®æ ‡ï¼š{', '.join(targets) if targets else 'ï¼ˆæ— ï¼‰'}"
        )
        return

    # é»˜è®¤å¤‡ä»½åŠŸèƒ½ï¼ˆæ ‡å‡†å¤‡ä»½ï¼‰
    try:
        data_dir = os.path.join(program_dir, "data")
        plugins_dir = os.path.join(program_dir, "plugins")
        import datetime

        now_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        # ä½¿ç”¨ä¸´æ—¶ç›®å½•æ”¾ç½®å¤‡ä»½ï¼Œé¿å…ä¸ç¨‹åºç›®å½•æ··æ·†
        import tempfile

        tmpdir = tempfile.gettempdir()
        backup_path = os.path.join(tmpdir, f"pagermaid_backup_{now_str}.tar.gz")
        sessions_path = os.path.join(tmpdir, f"pagermaid_sessions_{now_str}.tar.gz")

        await message.edit("ğŸ”„ æ­£åœ¨åˆ›å»ºæ ‡å‡†å¤‡ä»½...")
        # ä»…å¤‡ä»½ data + pluginsï¼ˆé»˜è®¤æ’é™¤ sessionï¼‰
        create_data_plugins_backup(
            backup_path, program_dir=program_dir, exclude_session=True, compresslevel=5
        )

        # sessions æ˜¯å¦éœ€è¦æ‰“åŒ…/ä¸Šä¼ ç”±é…ç½®æ§åˆ¶ï¼ˆupload_sessions: True/Falseï¼‰
        cfg = load_config()
        upload_sessions = bool(cfg.get("upload_sessions", False))
        sessions_created = None
        if upload_sessions:
            sessions_created = create_sessions_archive(
                sessions_path, program_dir=program_dir
            )

        await message.edit("ğŸ“¤ æ­£åœ¨ä¸Šä¼ å¤‡ä»½...")
        caption = f"ğŸ“¦ **Pagermaidæ ‡å‡†å¤‡ä»½**\n\nâ€¢ åˆ›å»ºæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nâ€¢ åŒ…å«: data (ä¸å« session) + plugins\nâ€¢ å¤‡ä»½ç±»å‹: æ ‡å‡†é…ç½®å¤‡ä»½"
        targets = get_target_chat_ids()
        if targets:
            # å¤šç›®æ ‡ä¼˜åŒ–ï¼šå…ˆä¸Šä¼ åˆ°æ”¶è—å¤¹å†è½¬å‘ï¼ˆé¿å…é‡å¤ä¸Šä¼ ï¼‰
            if len(targets) == 1:
                await message.client.send_file(
                    int(targets[0]), backup_path, caption=caption, force_document=True
                )
                if sessions_created:
                    await message.client.send_file(
                        int(targets[0]),
                        sessions_created,
                        caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                        force_document=True,
                    )
            else:
                sent_msg = await message.client.send_file(
                    "me", backup_path, caption=caption, force_document=True
                )
                for tgt in targets:
                    try:
                        await message.client.forward_messages(int(tgt), sent_msg, "me")
                    except Exception:
                        await message.client.send_file(
                            int(tgt), backup_path, caption=caption, force_document=True
                        )
                if sessions_created:
                    sent_s = await message.client.send_file(
                        "me",
                        sessions_created,
                        caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                        force_document=True,
                    )
                    for tgt in targets:
                        try:
                            await message.client.forward_messages(
                                int(tgt), sent_s, "me"
                            )
                        except Exception:
                            await message.client.send_file(
                                int(tgt),
                                sessions_created,
                                caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                                force_document=True,
                            )
        else:
            await message.client.send_file(
                "me", backup_path, caption=caption, force_document=True
            )
            if sessions_created:
                await message.client.send_file(
                    "me",
                    sessions_created,
                    caption="ğŸ” ä¼šè¯ï¼ˆsessionï¼‰å¤‡ä»½ â€” è¯·å¦¥å–„ä¿ç®¡ï¼ˆæ•æ„Ÿï¼‰",
                    force_document=True,
                )

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(backup_path):
                os.remove(backup_path)
        except Exception:
            pass
        try:
            if os.path.exists(sessions_path):
                os.remove(sessions_path)
        except Exception:
            pass

        if targets:
            await message.edit(
                f"âœ… æ ‡å‡†å¤‡ä»½å·²å®Œæˆ\n\nğŸ¯ **å·²å‘é€åˆ°:** {', '.join(targets)}\nğŸ“¦ **åŒ…å«:** é…ç½®æ–‡ä»¶ + æ’ä»¶ï¼ˆsession å·²å•ç‹¬å¤„ç†ï¼‰"
            )
        else:
            await message.edit(
                "âœ… æ ‡å‡†å¤‡ä»½å·²å®Œæˆ\n\nğŸ¯ **å·²ä¿å­˜åˆ°:** æ”¶è—å¤¹\nğŸ“¦ **åŒ…å«:** é…ç½®æ–‡ä»¶ + æ’ä»¶ï¼ˆsession å·²å•ç‹¬å¤„ç†ï¼‰"
            )
    except Exception as e:
        if "backup_path" in locals() and os.path.exists(backup_path):
            os.remove(backup_path)
        if "sessions_path" in locals() and os.path.exists(sessions_path):
            os.remove(sessions_path)
        await message.edit(f"âŒ å¤‡ä»½å¤±è´¥: {str(e)}")


# hf æ¢å¤å‘½ä»¤
@listener(command="hf", description="æ¢å¤å¤‡ä»½å‘½ä»¤ï¼Œæ”¯æŒç¡®è®¤æ¨¡å¼")
async def hf(message: Message):
    param = message.parameter

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¡®è®¤å‚æ•°
    if not param or param[0] != "confirm":
        # æ˜¾ç¤ºå®‰å…¨è­¦å‘Šå’Œç¡®è®¤ä¿¡æ¯
        warning_text = """âš ï¸ **å±é™©æ“ä½œè­¦å‘Š** âš ï¸

ğŸ”„ **æ¢å¤å¤‡ä»½å°†ä¼šï¼š**
â€¢ è¦†ç›–å½“å‰æ‰€æœ‰ data æ–‡ä»¶å¤¹å†…å®¹
â€¢ è¦†ç›–å½“å‰æ‰€æœ‰ plugins æ–‡ä»¶å¤¹å†…å®¹
â€¢ å¯èƒ½ä¸¢å¤±æœ€è¿‘çš„é…ç½®å’Œæ’ä»¶æ›´æ”¹
â€¢ éœ€è¦é‡å¯ Pagermaid æ‰èƒ½ç”Ÿæ•ˆ

ğŸ“‹ **æ¢å¤å‰å»ºè®®ï¼š**
â€¢ ç¡®è®¤å½“å‰æ²¡æœ‰é‡è¦æœªä¿å­˜çš„é…ç½®
â€¢ ç¡®è®¤è¦æ¢å¤çš„å¤‡ä»½æ˜¯æ­£ç¡®çš„ç‰ˆæœ¬
â€¢ ç³»ç»Ÿä¼šåœ¨ç¡®è®¤åè‡ªåŠ¨åˆ›å»ºä¸€æ¬¡â€œé˜²ä¸¢å¤±å…¨å¤‡ä»½â€å¹¶ä¸Šä¼ åˆ°æ”¶è—å¤¹ï¼ˆæ— éœ€æ‰‹åŠ¨è¿è¡Œ `bf`ï¼‰

ğŸ¯ **å°†è¦æ¢å¤çš„å¤‡ä»½ï¼š**"""

        try:
            await message.edit("ğŸ” æ­£åœ¨æ‰«æå¤‡ä»½æ–‡ä»¶...")
            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·å›å¤çš„å¤‡ä»½æ–‡ä»¶ï¼Œå…¶æ¬¡ä½¿ç”¨æ”¶è—å¤¹ä¸­æœ€æ–°çš„å¤‡ä»½
            backup_msg = None
            replied_msg = None
            try:
                replied_msg = await message.get_reply_message()
            except Exception:
                replied_msg = None

            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·å›å¤çš„ä»»ä½• .tar.gz å¤‡ä»½
            if (
                replied_msg
                and getattr(replied_msg, "file", None)
                and replied_msg.file.name
                and replied_msg.file.name.endswith(".tar.gz")
            ):
                # å½“å¯¹ç€å¤‡ä»½æ–‡ä»¶æ¢å¤æ—¶ï¼šå…ˆè‡ªåŠ¨ä¸‹è½½æ–‡ä»¶ç”¨äºåç»­ç¡®è®¤æ¢å¤
                program_dir = get_program_dir()
                temp_dir = os.path.join(program_dir, "data")
                os.makedirs(temp_dir, exist_ok=True)
                selected_temp_path = os.path.join(
                    temp_dir, "_hf_selected_backup.tar.gz"
                )
                try:
                    if os.path.exists(selected_temp_path):
                        os.remove(selected_temp_path)
                except Exception:
                    pass
                await message.edit("ğŸ“¥ æ­£åœ¨ä¸‹è½½ä½ å›å¤çš„å¤‡ä»½æ–‡ä»¶...")
                await message.client.download_media(
                    replied_msg, file=selected_temp_path
                )
                backup_msg = replied_msg
            else:
                # åœ¨æ”¶è—å¤¹ä¸­æŸ¥æ‰¾æœ€è¿‘çš„ .tar.gz å¤‡ä»½ï¼ˆå…¼å®¹ bf / bf all / bf p ç­‰ä¸åŒå‘½åï¼‰
                async for msg in message.client.iter_messages("me", limit=50):
                    if (
                        getattr(msg, "file", None)
                        and msg.file.name
                        and msg.file.name.endswith(".tar.gz")
                    ):
                        backup_msg = msg
                        break

            if not backup_msg:
                await message.edit(
                    "âŒ **æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶**\n\nâ€¢ è¯·å…ˆåˆ›å»ºä¸€ä¸ªå¤‡ä»½ï¼ˆ`bf`ï¼‰æˆ–ç›´æ¥å›å¤ä¸€ä¸ªå¤‡ä»½æ–‡ä»¶åå†æ¬¡æ‰§è¡Œ `hf`\nâ€¢ ç¡®ä¿å¤‡ä»½æ–‡ä»¶åœ¨æ”¶è—å¤¹æˆ–å½“å‰å¯¹è¯ä¸­å¯è§"
                )
                return

            # è§£æå¤‡ä»½æ–‡ä»¶ä¿¡æ¯
            file_name = backup_msg.file.name
            file_size = round(backup_msg.file.size / 1024 / 1024, 2)  # MB
            backup_date = backup_msg.date.strftime("%Y-%m-%d %H:%M:%S")

            warning_text += f"\nâ€¢ **æ–‡ä»¶å:** `{file_name}`\nâ€¢ **æ–‡ä»¶å¤§å°:** {file_size} MB\nâ€¢ **åˆ›å»ºæ—¶é—´:** {backup_date}\n\n"
            # è‹¥æ¥è‡ªå›å¤ï¼Œå·²åœ¨ä¸Šæ–¹è‡ªåŠ¨ä¸‹è½½ï¼Œæ— éœ€å†æ¬¡ä¸‹è½½
            if (
                replied_msg
                and backup_msg
                and (backup_msg.id == getattr(replied_msg, "id", None))
            ):
                warning_text += """å·²è‡ªåŠ¨ä¸‹è½½è¯¥å¤‡ä»½æ–‡ä»¶ã€‚
âœ… **ç¡®è®¤æ¢å¤è¯·è¾“å…¥:**
`hf confirm`

âŒ **å–æ¶ˆæ“ä½œè¯·å¿½ç•¥æ­¤æ¶ˆæ¯**"""
            else:
                warning_text += """âœ… **ç¡®è®¤æ¢å¤è¯·è¾“å…¥:**
`hf confirm`

âŒ **å–æ¶ˆæ“ä½œè¯·å¿½ç•¥æ­¤æ¶ˆæ¯**"""

            await message.edit(warning_text)
            return

        except Exception as e:
            await message.edit(f"âŒ **æ‰«æå¤±è´¥:** {str(e)}")
            return

    # ç”¨æˆ·å·²ç¡®è®¤ï¼Œå¼€å§‹æ¢å¤æµç¨‹
    try:
        # ä¼˜å…ˆä½¿ç”¨é¢„ä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆå½“ç”¨æˆ·å¯¹å¤‡ä»½æ¶ˆæ¯å›å¤æ‰§è¡Œ hf æ—¶ä¼šç”Ÿæˆï¼‰
        program_dir = get_program_dir()
        selected_temp_path = os.path.join(
            program_dir, "data", "_hf_selected_backup.tar.gz"
        )
        pgm_backup_zip_name = None
        temp_extract_dir = None

        if os.path.exists(selected_temp_path):
            await message.edit(
                "âœ… **ç”¨æˆ·å·²ç¡®è®¤ï¼Œå¼€å§‹æ¢å¤æµç¨‹**\n\nâ€¢ å·²é€‰æ‹©å›å¤çš„å¤‡ä»½æ–‡ä»¶ï¼Œå‡†å¤‡è§£å‹..."
            )
            pgm_backup_zip_name = selected_temp_path
        else:
            await message.edit(
                "âœ… **ç”¨æˆ·å·²ç¡®è®¤ï¼Œå¼€å§‹æ¢å¤æµç¨‹**\n\nâ€¢ æ­£åœ¨è·å–æœ€æ–°å¤‡ä»½..."
            )
            # ä¼˜å…ˆä½¿ç”¨å›å¤çš„å¤‡ä»½æ–‡ä»¶ï¼Œå…¶æ¬¡è·å–æ”¶è—å¤¹ä¸­çš„æœ€æ–°å¤‡ä»½
            backup_msg = None
            replied_msg = None
            try:
                replied_msg = await message.get_reply_message()
            except Exception:
                replied_msg = None

            # å†æ¬¡ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·å›å¤çš„ä»»ä½• .tar.gz å¤‡ä»½
            if (
                replied_msg
                and getattr(replied_msg, "file", None)
                and replied_msg.file.name
                and replied_msg.file.name.endswith(".tar.gz")
            ):
                backup_msg = replied_msg
            else:
                async for msg in message.client.iter_messages("me", limit=50):
                    if (
                        getattr(msg, "file", None)
                        and msg.file.name
                        and msg.file.name.endswith(".tar.gz")
                    ):
                        backup_msg = msg
                        break

            if not backup_msg:
                await message.edit("âŒ **æ¢å¤å¤±è´¥**\n\nâ€¢ æœªæ‰¾åˆ°ä»»ä½•å¤‡ä»½æ–‡ä»¶")
                return

            await message.edit("ğŸ“¥ **æ­£åœ¨ä¸‹è½½å¤‡ä»½æ–‡ä»¶...**")
            pgm_backup_zip_name = await message.client.download_media(
                backup_msg, file="pagermaid_backup.tar.gz"
            )

        await message.edit("ğŸ—ƒï¸ **æ­£åœ¨è§£å‹å¤‡ä»½æ–‡ä»¶...**")
        program_dir = get_program_dir()

        # ä½¿ç”¨ä¸´æ—¶ç›®å½•è§£å‹ï¼Œé¿å…ç›´æ¥è§£å‹åˆ°æ ¹ç›®å½•å¯¼è‡´æ··ä¹±
        temp_extract_dir = os.path.join(program_dir, "_tmp_restore")
        try:
            if os.path.exists(temp_extract_dir):
                shutil.rmtree(temp_extract_dir)
            os.makedirs(temp_extract_dir, exist_ok=True)
        except Exception:
            pass

        if not un_tar_gz(pgm_backup_zip_name, temp_extract_dir):
            os.remove(pgm_backup_zip_name)
            if os.path.exists(temp_extract_dir):
                shutil.rmtree(temp_extract_dir)
            await message.edit(
                "âŒ **è§£å‹å¤±è´¥**\n\nâ€¢ å¤‡ä»½æ–‡ä»¶å¯èƒ½æŸå\nâ€¢ è¯·é‡æ–°ä¸‹è½½å¤‡ä»½"
            )
            return

        # åˆ é™¤å‹ç¼©åŒ…
        os.remove(pgm_backup_zip_name)

        # å°è¯•è¯†åˆ«å¤‡ä»½æ ¹ç›®å½•
        final_backup_folder = os.path.join(temp_extract_dir, "pagermaid_backup")
        if not os.path.exists(final_backup_folder):
            # å…¼å®¹æ—§åŒ…ç»“æ„ï¼šå–ä¸´æ—¶ç›®å½•ä¸‹çš„å”¯ä¸€é¡¶çº§ç›®å½•ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ä¸´æ—¶ç›®å½•
            top_items = [
                os.path.join(temp_extract_dir, x) for x in os.listdir(temp_extract_dir)
            ]
            dirs = [p for p in top_items if os.path.isdir(p)]
            files = [p for p in top_items if os.path.isfile(p)]
            if len(dirs) == 1 and not files:
                final_backup_folder = dirs[0]
            elif {"data", "plugins"} & {os.path.basename(d) for d in dirs}:
                final_backup_folder = temp_extract_dir
            else:
                raise Exception("å¤‡ä»½åŒ…ç»“æ„å¼‚å¸¸ï¼šç¼ºå°‘ data/plugins ç›®å½•")

        # æ¢å¤å‰è‡ªåŠ¨åˆ›å»ºä¸€æ¬¡å½“å‰çŠ¶æ€çš„æ ‡å‡†å…¨å¤‡ä»½ï¼ˆdata+pluginsï¼‰åˆ°æ”¶è—å¤¹
        try:
            data_dir = os.path.join(program_dir, "data")
            plugins_dir = os.path.join(program_dir, "plugins")
            import datetime

            now_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_backup_filename = f"pre_restore_backup_{now_str}.tar.gz"
            create_tar_gz([data_dir, plugins_dir], safe_backup_filename)
            caption = f"ğŸ›Ÿ æ¢å¤å‰è‡ªåŠ¨å…¨å¤‡ä»½\n\nâ€¢ åˆ›å»ºæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nâ€¢ åŒ…å«: data + plugins"
            await message.client.send_file("me", safe_backup_filename, caption=caption)
            os.remove(safe_backup_filename)
        except Exception:
            # å¤‡ä»½å¤±è´¥ä¸é˜»å¡æ¢å¤æµç¨‹ï¼Œä»…å¿½ç•¥
            pass

        await message.edit("ğŸ”„ **æ­£åœ¨æ¢å¤æ–‡ä»¶...**")

        # å°†è§£å‹å‡ºçš„å†…å®¹é‡Šæ”¾åˆ°ç¨‹åºæ ¹ç›®å½•ï¼Œè·³è¿‡ session æ–‡ä»¶ï¼ˆé¿å…è¦†ç›–ä¼šè¯ç™»é™†çŠ¶æ€ï¼‰
        def _is_session_file(path: str) -> bool:
            name = os.path.basename(path)
            return name.endswith(".session") or name.endswith(".session-journal")

        for item in os.listdir(final_backup_folder):
            src_path = os.path.join(final_backup_folder, item)
            dest_path = os.path.join(program_dir, item)
            if os.path.isdir(src_path):
                # ç›®å½•å¤åˆ¶ï¼šé€æ–‡ä»¶éå†ä»¥è·³è¿‡ session æ–‡ä»¶
                for root, dirs, files in os.walk(src_path):
                    rel_root = os.path.relpath(root, src_path)
                    target_root = (
                        os.path.join(dest_path, rel_root)
                        if rel_root != "."
                        else dest_path
                    )
                    os.makedirs(target_root, exist_ok=True)
                    for fname in files:
                        s = os.path.join(root, fname)
                        if _is_session_file(s):
                            continue
                        d = os.path.join(target_root, fname)
                        os.makedirs(os.path.dirname(d), exist_ok=True)
                        shutil.copy2(s, d)
            else:
                if _is_session_file(src_path):
                    continue
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                shutil.copy2(src_path, dest_path)

        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(temp_extract_dir, ignore_errors=True)
        # å¦‚ä½¿ç”¨äº†é¢„ä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶ï¼Œæ¢å¤å®Œæˆååˆ é™¤
        try:
            if pgm_backup_zip_name == selected_temp_path and os.path.exists(
                selected_temp_path
            ):
                os.remove(selected_temp_path)
        except Exception:
            pass

        await message.edit(
            "âœ… **å¤‡ä»½æ¢å¤å®Œæˆ**\n\nâ€¢ æ‰€æœ‰æ–‡ä»¶å·²æ¢å¤\nâ€¢ å·²åœ¨æ”¶è—å¤¹ä¿å­˜æ¢å¤å‰çš„å…¨å¤‡ä»½\nâ€¢ è¯·è¾“å…¥ `-restart` é‡å¯ç”Ÿæ•ˆ"
        )

    except Exception as e:
        # å¤±è´¥æ—¶å°½é‡æ¸…ç†ä¸´æ—¶èµ„æº
        try:
            if (
                "temp_extract_dir" in locals()
                and temp_extract_dir
                and os.path.exists(temp_extract_dir)
            ):
                shutil.rmtree(temp_extract_dir, ignore_errors=True)
        except Exception:
            pass
        try:
            if (
                "pgm_backup_zip_name" in locals()
                and pgm_backup_zip_name
                and os.path.exists(pgm_backup_zip_name)
            ):
                # ä»…åˆ é™¤æˆ‘ä»¬ä¸‹è½½åˆ°å½“å‰ç›®å½•çš„ä¸´æ—¶åŒ…æˆ–é¢„ä¸‹è½½é€‰æ‹©çš„åŒ…
                if pgm_backup_zip_name.endswith(
                    "pagermaid_backup.tar.gz"
                ) or pgm_backup_zip_name.endswith("_hf_selected_backup.tar.gz"):
                    os.remove(pgm_backup_zip_name)
        except Exception:
            pass
        await message.edit(
            f"âŒ **æ¢å¤å¤±è´¥**\n\nâ€¢ é”™è¯¯ä¿¡æ¯: {str(e)}\nâ€¢ è¯·æ£€æŸ¥å¤‡ä»½æ–‡ä»¶æ˜¯å¦å®Œæ•´"
        )
